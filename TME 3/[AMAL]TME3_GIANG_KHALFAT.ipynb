{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8ec495",
   "metadata": {},
   "source": [
    "### Etudiant 1: GIANG Phuong-Thu, Cécile (3530406)\n",
    "### Etudiant 1: KHALFAT Célina (28716860)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c03f20",
   "metadata": {},
   "source": [
    "# TME 3 - Chargement de données, GPU et checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c750b",
   "metadata": {},
   "source": [
    "Dans ce TME, nous finissons notre revue de PyTorch en montrant comment :\n",
    "- définir des classes permettant de représenter les données d’apprentissage\n",
    "- passer sur GPU\n",
    "- faire en sorte de pouvoir reprendre un apprentissage après une interruption volontaire ou non (checkpointing)\n",
    "\n",
    "Les données utilisées tout le long de ce TME sont la _base de chiffres manuscrites **MNIST**_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81724e94",
   "metadata": {},
   "source": [
    "## 1 - Gérer les données avec `Dataset` et `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f6d784",
   "metadata": {},
   "source": [
    "Nous implémentons une classe `MNISTDataset` héritant de `Dataset`. Cette classe nous permettra de manipuler le jeu de données MNIST. En particulier:\n",
    "- la méthode `__getitem__` nous permet de récupérer un couple (exemple, label) dans notre base de données\n",
    "- la méthode `__len__` renvoie la taille du jeu de données\n",
    "\n",
    "Nous chargeons ensuite nos données d'apprentissage et de test dans une instance de Dataloader qui est un itérateur sur nos données, et qui permet de spécifier la taille des batchs, s'il faut mélanger ou pas les données et de charger les données en parallèle\n",
    "\n",
    "Afin de pouvoir par la suite comparer des résultats de différentes fonctions appliquées sur nos données, nous donnons en paramètre de nos `DataLoader` une graine afin de toujours séparer nos données en les mêmes batchs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a533bda8",
   "metadata": {},
   "source": [
    "## 2 - Implémentation d'un auto-encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e0132",
   "metadata": {},
   "source": [
    "Nous implémentons une classe `AutoEncoder` héritant de la classe `Module` fournie par `PyTorch`, et qui suit l'architecture suivante: `linéaire → ReLU` pour la partie codage, et `linéaire → sigmoide` pour la partie décodage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58376839",
   "metadata": {},
   "source": [
    "## 3 - Campagne d'expériences sur l'auto-encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf315767",
   "metadata": {},
   "source": [
    "Nous définissons maintenant une fonction `autoencoding_neuralnet` prenant en paramètre la dimension de l'espace latent dans lequel projeter nos données pour la partie codage. Cette fonction effectuera un apprentissage sur notre auto-encodeur afin de minimiser le coût **BCE** _(Binary Cross-Entropy)_ entre les images de notre base MNIST et les reconstructions faites par notre réseau lors de la phase forward.\n",
    "\n",
    "En particulier, nous spécifions à notre fonction de charger les données et notre modèle en GPU si celui-ci est disponible afin d'accélérer nos calculs. Nous faisons également attention à sauvegarder au fur et à mesure de l’apprentissage notre modèle afin\n",
    "par exemple de pouvoir reprendre les calculs en cas d’interruption _(checkpointing)_.\n",
    "\n",
    "Nous observons les loss en apprentissage et en test pour différentes valeurs de dimensions latentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01222d21",
   "metadata": {},
   "source": [
    "**Projection dans un espace de dimension 32:**\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"images/auto_32_train.png\" width=300 height=480></td>\n",
    "    <td><img src=\"images/auto_32_test.png\" width=300 height=480></td>\n",
    "  </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b17a3a",
   "metadata": {},
   "source": [
    "**Projection dans un espace de dimension 64:**\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"images/auto_64_train.png\" width=300 height=480></td>\n",
    "    <td><img src=\"images/auto_64_test.png\" width=300 height=480></td>\n",
    "  </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc45ec80",
   "metadata": {},
   "source": [
    "**Projection dans un espace de dimension 128:**\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"images/auto_128_train.png\" width=300 height=480></td>\n",
    "    <td><img src=\"images/auto_128_test.png\" width=300 height=480></td>\n",
    "  </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1827806",
   "metadata": {},
   "source": [
    "**Projection dans un espace de dimension 256:**\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"images/auto_256_train.png\" width=300 height=480></td>\n",
    "    <td><img src=\"images/auto_256_test.png\" width=300 height=480></td>\n",
    "  </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f7738",
   "metadata": {},
   "source": [
    "Nous observons que plus l'espace de projection est grand, plus la loss est faible: la perte d'information lors du passage en petite dimension est bien moins important lorsque nous conservons un grand nombre de descripteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407d4da",
   "metadata": {},
   "source": [
    "**Images reconstruites**\n",
    "\n",
    "Ci-dessous nous affichons de gauche à droite une image issue de la base MNIST, puis ses reconstructions pour des espaces latents de respectivement 32, 64, 128 et 256.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"images/auto_init.png\" width=300 height=480></td>\n",
    "    <td><img src=\"images/auto_32.png\" width=300 height=480></td>\n",
    "     <td><img src=\"images/auto_64.png\" width=300 height=480></td>\n",
    "     <td><img src=\"images/auto_128.png\" width=300 height=480></td>\n",
    "     <td><img src=\"images/auto_256.png\" width=300 height=480></td>\n",
    "  </tr>\n",
    " </table>\n",
    " \n",
    " Les images obtenues viennent confirmer nos observations ci-dessus: les images reconstruites après projection sur des espace de plus grande dimension se rapprochent bien plus de l'image originale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564b142",
   "metadata": {},
   "source": [
    "## 4 - Highway Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac4be3",
   "metadata": {},
   "source": [
    "Un problème posé par des réseaux de neurones à couches multiples est qu'ils peuvent être sujets à ce qu'on appelle le _**vanishing gradient problem**_ (problème de dissipation du gradient): plus un réseau contient de couches, plus le gradient de la loss se dissipe lors de la phase de backpropagation à travers ces différentes couches. Au final, le gradient devient presque nul et il n'y a quasiment aucune mise à jour sur les paramètres à optimiser.\n",
    "\n",
    "Pour palier à ce problème, l'article ci-dessous introduit le concept de **Highway Network**:\n",
    "https://arxiv.org/pdf/1505.00387.pdf\n",
    "\n",
    "Au lieu de considérer un réseau classique où un module $H$ (donc une couche de notre réseau) correspond à une transformation affine suivie d'une activation non-linéaire, nous définissons maintenant pour chaque couche deux transformations non-linéaires supplémentaires que nous noterons $T$ _(transform gate)_ et $C$ _(carry gate)_. En règle générale, nous prendrons $C = 1 - T$.\n",
    "\n",
    "La sortie de chaque couche est désormais définie ainsi:\n",
    "$$ y = H(x,w_H)· T(x,w_T) + x · (1 − T(x,w_T)) $$\n",
    "\n",
    "Nous comprenons donc que les transformations $T$ et $C$ permettent de déterminer à quel point nous prenons en compte la transformation $H$: plus $T$ est proche de 1, plus la sortie correspond à la transformation $H(x,w_H)$. Au contraire, plus $T$ est proche de 0, plus $C$ tend vers 1 et donc aucune tranformation n'est appliquée à l'entrée $x$: la couche ne fait que laisser passer $x$.\n",
    "\n",
    "Nous implémentons maintenant une classe `Highway` héritant de la classe `Module`.\n",
    "\n",
    "Nous fixerons ainsi nos différentes transformations:\n",
    "- $H$ est une transformation linéaire suivie d'une activation ReLU\n",
    "- $T$ est une transformation linéaire suivie de la fonction non-linéaire sigmoïde\n",
    "- $C$ correspond à $1 - T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b1b59",
   "metadata": {},
   "source": [
    "## 3 - Campagne d'expériences sur Highway Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6051b2",
   "metadata": {},
   "source": [
    "Nous testons notre réseau sur différents nombres de couches. \n",
    "\n",
    "Nous définissons une fonction `highway_neuralnet` prenant en paramètre le nombre de couches de notre réseau de neurones. La loss à minimiser est là encore **BCE**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414dac4",
   "metadata": {},
   "source": [
    "**Highway Network à 5 couches:**\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"images/highway_5_train.png\" width=300 height=480></td>\n",
    "    <td><img src=\"images/highway_5_test.png\" width=300 height=480></td>\n",
    "  </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2492199",
   "metadata": {},
   "source": [
    "**Highway Network à 10 couches:**\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"images/highway_10_train.png\" width=300 height=480></td>\n",
    "    <td><img src=\"images/highway_10_test.png\" width=300 height=480></td>\n",
    "  </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc53879",
   "metadata": {},
   "source": [
    "**Images reconstruites**\n",
    "\n",
    "De gauche à droite: image initiale tirée de la base MNIST, reconstruction avec 5 couches, reconstruction avec 10 couches.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"images/highway_init.png\" width=300 height=480></td>\n",
    "    <td><img src=\"images/highway_5.png\" width=300 height=480></td>\n",
    "     <td><img src=\"images/highway_10.png\" width=300 height=480></td>\n",
    "  </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f5de6",
   "metadata": {},
   "source": [
    "Nous observons que plus le nombre de couches est élevée, plus la loss est élevée. Elle est cependant moins élevée qu'elle l'aurait été pour un réseau classique avec autant de couches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
